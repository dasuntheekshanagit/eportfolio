export const projectsData = [
  {
    id: 'arcombat',
    title: 'ARCombat | First-Person AR Game with Localization',
    shortDescription: 'Groundbreaking first-person AR game integrating VR and AR technologies for immersive multiplayer experiences with custom 3D printed hardware.',
    fullDescription: `ARCombat is a revolutionary first-person augmented reality game that seamlessly integrates VR and AR technologies to create an immersive multiplayer gaming experience. This project represents a significant advancement in interactive entertainment technology.

The game features custom-designed 3D printed hardware components including specialized guns, triggers, and reload mechanisms that enhance the physical interaction with the virtual environment. Players can engage in realistic combat scenarios while experiencing the thrill of augmented reality gaming.

Key technical achievements include real-time localization systems, multiplayer networking capabilities, and sophisticated hardware-software integration. The project demonstrates expertise in embedded systems, IoT connectivity, and advanced AR/VR development.

The development process involved extensive research in computer vision, sensor fusion, and real-time graphics rendering. The team successfully created a scalable platform that can accommodate multiple players simultaneously while maintaining high performance and accuracy.`,
    tags: ['Embedded Systems', 'IoT', 'Augmented Reality', 'Computer Vision', 'Unity', 'C++', 'Hardware Design'],
    technologies: ['Unity 3D', 'ARCore', 'ESP32', 'C++', 'Python', 'Computer Vision', '3D Printing', 'Networking'],
    category: 'AR/VR',
    featured: true,
    status: 'Completed',
    duration: '8 months',
    teamSize: '4 members',
    role: 'Hardware Lead & AR Developer',
    challenges: [
      'Real-time tracking and localization in dynamic environments',
      'Hardware-software synchronization for responsive gameplay',
      'Multiplayer networking with low latency requirements',
      'Battery optimization for extended gameplay sessions'
    ],
    achievements: [
      '3rd Place at IEEE Innovation Nation Sri Lanka 2023',
      'Successfully demonstrated at multiple tech exhibitions',
      'Featured in university research publications'
    ],
    links: {
      demo: 'https://cepdnaclk.github.io/e19-3yp-First-Person-AR-Game-with-Localization/',
      github: 'https://github.com/cepdnaclk/e19-3yp-First-Person-AR-Game-with-Localization',
      video: 'https://youtube.com/watch?v=demo-video'
    },
    images: [
      '/images/arcombat-1.jpg',
      '/images/arcombat-2.jpg',
      '/images/arcombat-3.jpg'
    ]
  },
  {
    id: 'baby-development',
    title: 'Baby Development Tracking System',
    shortDescription: 'Comprehensive system to track developmental milestones of infants with AI chatbot "Nanny" for guidance and support to caregivers.',
    fullDescription: `The Baby Development Tracking System is a comprehensive mobile application designed to monitor and manage the developmental milestones of infants aged 0 to 5 years. This innovative solution serves parents, guardians, public health midwives (PHM), and doctors by providing a centralized platform for infant care management.

The system features an intelligent AI chatbot named "Nanny" that provides personalized guidance and support to users. Nanny can answer questions about child development, provide recommendations based on the child's current stage, and alert caregivers about important milestones or potential concerns.

Key functionalities include vaccination tracking, growth monitoring (weight and height), milestone recording, and automated notifications for upcoming appointments or vaccinations. The system also provides standard recommendations based on medical guidelines and best practices in pediatric care.

The application utilizes Firebase for real-time data synchronization and secure cloud storage, ensuring that all stakeholders have access to up-to-date information about the child's development. The user interface is designed to be intuitive and accessible for users with varying levels of technical expertise.`,
    tags: ['Java', 'Firebase', 'Mobile App', 'AI Chatbot', 'Healthcare'],
    technologies: ['Java', 'Android Studio', 'Firebase', 'Machine Learning', 'Natural Language Processing', 'Cloud Functions'],
    category: 'Mobile Development',
    featured: true,
    status: 'Completed',
    duration: '6 months',
    teamSize: '5 members',
    role: 'Backend Developer & AI Integration',
    challenges: [
      'Implementing secure healthcare data management',
      'Creating an intuitive AI chatbot for non-technical users',
      'Ensuring real-time synchronization across multiple user types',
      'Compliance with healthcare data privacy regulations'
    ],
    achievements: [
      'Successfully deployed to beta testing with 50+ families',
      'Positive feedback from healthcare professionals',
      'Featured in university mobile app showcase'
    ],
    links: {
      demo: 'https://cepdnaclk.github.io/e19-co225-Baby-Developement-Tracking-System-Mobileapplication/',
      github: 'https://github.com/cepdnaclk/e19-co225-Baby-Developement-Tracking-System-Mobileapplication'
    },
    images: [
      '/images/baby-dev-1.jpg',
      '/images/baby-dev-2.jpg'
    ]
  },
  {
    id: 'keyboard-visually-impaired',
    title: 'Keyboard for the Visually Impaired',
    shortDescription: 'Innovative keyboard using Braille patterns with auditory feedback, supporting 50+ characters and wireless connectivity for enhanced accessibility.',
    fullDescription: `This project addresses the critical need for accessible computing solutions for visually impaired individuals. The innovative keyboard design utilizes standard Braille alphabet patterns, making it intuitive for users already familiar with Braille reading.

The keyboard features 9 strategically positioned pushbuttons, each with distinct tactile characteristics to enable accurate character input. Through precise key combinations, users can generate over 50 different characters, covering the complete alphabet, numbers, and common punctuation marks.

A key innovation is the integrated auditory feedback system that provides real-time voice responses for each typed character. This feature significantly enhances user confidence and typing accuracy by confirming input in real-time. The system supports multiple languages and can be customized for different voice preferences.

Wireless connectivity is achieved through both Wi-Fi and Bluetooth protocols, ensuring compatibility with a wide range of devices including computers, tablets, and smartphones. The device is powered by an efficient microcontroller system that manages input processing, audio generation, and wireless communication.

The project demonstrates expertise in embedded systems programming, human-computer interaction design, and accessibility technology development. Special attention was paid to ergonomic design and durability to ensure long-term usability.`,
    tags: ['IoT', 'C Programming', 'Accessibility', 'Embedded Systems', 'Braille'],
    technologies: ['C', 'Arduino', 'ESP32', 'Bluetooth', 'Wi-Fi', 'Audio Processing', 'PCB Design'],
    category: 'Hardware/IoT',
    featured: true,
    status: 'Completed',
    duration: '4 months',
    teamSize: '3 members',
    role: 'Lead Developer & Hardware Designer',
    challenges: [
      'Implementing accurate Braille pattern recognition',
      'Optimizing power consumption for extended battery life',
      'Creating clear and responsive audio feedback',
      'Ensuring reliable wireless connectivity across devices'
    ],
    achievements: [
      'Successfully tested with visually impaired users',
      'Demonstrated 95% accuracy in character recognition',
      'Received positive feedback from accessibility organizations'
    ],
    links: {
      demo: 'https://cepdnaclk.github.io/e19-co227-Keyboard-for-Visually-Impaired/',
      github: 'https://github.com/cepdnaclk/e19-co227-Keyboard-for-Visually-Impaired'
    },
    images: [
      '/images/keyboard-1.jpg',
      '/images/keyboard-2.jpg'
    ]
  },
  {
    id: 'escal-website',
    title: 'ESCAL Website',
    shortDescription: 'Contributed to developing the new website for the Embedded Systems and Computer Architecture Laboratory (ESCAL) using Jekyll and GitHub Pages.',
    fullDescription: `The ESCAL (Embedded Systems and Computer Architecture Laboratory) website project involved creating a comprehensive online presence for one of the premier research laboratories at the Department of Computer Engineering, University of Peradeniya.

This project utilized Jekyll as the static site generator, providing a modern, fast, and maintainable web platform. The website showcases the laboratory's research themes, ongoing projects, team members, publications, and available resources for students and researchers.

Key features include a responsive design that works seamlessly across all devices, an intuitive navigation structure, and a content management system that allows easy updates by laboratory staff. The site includes detailed project portfolios, research publication listings, and team member profiles.

The development process involved close collaboration with laboratory staff to understand their requirements and create a user-friendly interface that effectively communicates their research activities. Special attention was paid to performance optimization and search engine optimization to ensure maximum visibility.

The project enhanced my skills in Jekyll, Liquid templating, HTML5, CSS3, and responsive web design. Additionally, I gained valuable experience in collaborative development using Git and GitHub, working with multiple contributors to maintain code quality and consistency.`,
    tags: ['Jekyll', 'Web Development', 'Static Site Generator', 'GitHub Pages'],
    technologies: ['Jekyll', 'Liquid', 'HTML5', 'CSS3', 'JavaScript', 'GitHub Pages', 'Git'],
    category: 'Web Development',
    featured: false,
    status: 'Completed',
    duration: '3 months',
    teamSize: '6 members',
    role: 'Frontend Developer & Content Manager',
    challenges: [
      'Creating a flexible content management system',
      'Ensuring fast loading times for research content',
      'Implementing responsive design for academic content',
      'Coordinating with multiple content contributors'
    ],
    achievements: [
      'Successfully launched and maintained laboratory website',
      'Improved laboratory online visibility by 200%',
      'Streamlined content update process for staff'
    ],
    links: {
      demo: 'http://escal.ce.pdn.ac.lk/',
      github: 'https://github.com/cepdnaclk/escal-new'
    },
    images: [
      '/images/escal-1.jpg',
      '/images/escal-2.jpg'
    ]
  },
  {
    id: 'text-adventure-game',
    title: 'Python Based Text Adventure Game Based on Linux Terminal',
    shortDescription: 'Developed \'Quest for the Hidden Ticket,\' a web-based game utilizing Linux terminal commands for newcomers in the Department of Computer Engineering.',
    fullDescription: `"Quest for the Hidden Ticket" is an innovative educational game designed specifically for newcomers to the Department of Computer Engineering at the University of Peradeniya. This web-based text adventure game serves as an engaging introduction to Linux terminal commands and basic system navigation.

The game creates an immersive virtual environment where players explore the department, solve puzzles, and discover hidden secrets using real Linux commands. Players must navigate through different locations within the university, interact with virtual objects, and complete challenges that mirror real-world computing scenarios.

Built using Python and Flask, the game features a robust backend that processes terminal commands and maintains game state across sessions. The web interface provides a terminal-like experience while remaining accessible to users who may not have direct access to a Linux system.

Educational objectives include familiarizing students with essential Linux commands such as ls, cd, cat, grep, and find, while also introducing concepts like file permissions, directory structures, and basic shell scripting. The game progressively increases in complexity, ensuring that players build confidence as they advance.

The project is open-source, encouraging contributions from fellow developers and allowing for continuous improvement and expansion of game content. This collaborative approach has led to the addition of new challenges and features based on user feedback.`,
    tags: ['Full-Stack Development', 'Flask', 'Python', 'Educational Gaming', 'Linux'],
    technologies: ['Python', 'Flask', 'HTML5', 'CSS3', 'JavaScript', 'Linux', 'Shell Scripting'],
    category: 'Web Development',
    featured: false,
    status: 'Completed',
    duration: '2 months',
    teamSize: '2 members',
    role: 'Full-Stack Developer & Game Designer',
    challenges: [
      'Simulating realistic Linux terminal behavior in web browser',
      'Creating engaging educational content for technical concepts',
      'Implementing secure command execution in web environment',
      'Balancing game difficulty for diverse skill levels'
    ],
    achievements: [
      'Successfully used by 100+ new students',
      'Integrated into department orientation program',
      'Received positive feedback from faculty and students'
    ],
    links: {
      github: 'https://github.com/dasuntheekshanagit/e20welcome'
    },
    images: [
      '/images/game-1.jpg',
      '/images/game-2.jpg'
    ]
  },
  {
    id: 'smart-bus-system',
    title: 'Smart Bus Ticket System',
    shortDescription: 'Created a smart bus ticket system enabling passengers to reserve seats, track bus locations, and notify drivers of their desired exit points.',
    fullDescription: `The Smart Bus Ticket System represents a comprehensive solution to modernize public transportation through technology integration. This system addresses common challenges faced by bus passengers including seat availability, route tracking, and communication with drivers.

The system allows passengers to reserve seats in advance through a mobile application, eliminating the uncertainty of finding available seats during peak hours. Real-time GPS tracking enables passengers to monitor bus locations and estimated arrival times, improving travel planning and reducing waiting times.

A unique feature is the passenger notification system that allows travelers to inform drivers of their intended exit points. This feature is particularly valuable for tourists or occasional travelers who may not be familiar with specific stops along the route.

The backend infrastructure utilizes cloud services to manage real-time data synchronization between multiple buses, passengers, and the central management system. The system includes features for route optimization, passenger analytics, and driver performance monitoring.

Technical implementation involved developing mobile applications for both passengers and drivers, a web-based management dashboard for bus operators, and IoT devices for real-time location tracking and passenger counting.`,
    tags: ['IoT', 'Mobile Development', 'GPS Tracking', 'Real-time Systems', 'Transportation'],
    technologies: ['Java', 'Android', 'Firebase', 'GPS', 'Google Maps API', 'IoT Sensors', 'Cloud Computing'],
    category: 'Mobile Development',
    featured: false,
    status: 'Prototype',
    duration: '5 months',
    teamSize: '4 members',
    role: 'Mobile App Developer & System Architect',
    challenges: [
      'Implementing accurate real-time location tracking',
      'Managing high-frequency data updates from multiple buses',
      'Creating intuitive user interfaces for diverse user groups',
      'Ensuring system reliability during peak usage periods'
    ],
    achievements: [
      'Finalist at IEEE Innovation Nation Sri Lanka 2022',
      'Successfully demonstrated with local bus operators',
      'Received interest from transportation authorities'
    ],
    links: {
      github: 'https://github.com/dasuntheekshanagit/smart-bus-system'
    },
    images: [
      '/images/bus-system-1.jpg',
      '/images/bus-system-2.jpg'
    ]
  },
  {
    id: 'zero-cost-notepad',
    title: 'Zero Cost NotePad',
    shortDescription: 'Innovative note-taking solution using image processing and machine learning to create digital notes with a pen on reusable surfaces.',
    fullDescription: `Zero Cost NotePad is a revolutionary note-taking solution that combines computer vision, machine learning, and innovative thinking to create a sustainable and cost-effective alternative to traditional paper-based note-taking.

The system uses advanced image processing algorithms to capture and digitize handwritten notes made with a regular pen on any reusable surface. Through sophisticated computer vision techniques, the system can accurately recognize text, diagrams, and sketches, converting them into digital format for storage and sharing.

Machine learning models are employed to improve handwriting recognition accuracy over time, adapting to individual writing styles and preferences. The system supports multiple languages and can handle various writing instruments and surface types.

Environmental sustainability is a core principle of this project. By eliminating the need for paper, the system contributes to reducing deforestation and waste generation. The reusable surfaces can be cleaned and used indefinitely, making this a truly zero-cost solution after initial setup.

The project demonstrates expertise in computer vision, machine learning, image processing, and sustainable technology development. Advanced algorithms for noise reduction, edge detection, and character recognition ensure high-quality digital output regardless of lighting conditions or surface irregularities.`,
    tags: ['Computer Vision', 'Machine Learning', 'Image Processing', 'Sustainability', 'Python'],
    technologies: ['Python', 'OpenCV', 'TensorFlow', 'Scikit-learn', 'NumPy', 'PIL', 'OCR'],
    category: 'AI/ML',
    featured: false,
    status: 'Completed',
    duration: '24 hours (Hackathon)',
    teamSize: '3 members',
    role: 'ML Engineer & Computer Vision Developer',
    challenges: [
      'Achieving high accuracy in handwriting recognition',
      'Handling various lighting conditions and surface types',
      'Real-time processing for immediate feedback',
      'Creating a user-friendly interface for non-technical users'
    ],
    achievements: [
      'Winner of ACES Hackathon 2023',
      'Demonstrated 90%+ accuracy in text recognition',
      'Featured in university innovation showcase'
    ],
    links: {
      github: 'https://github.com/dasuntheekshanagit/zero-cost-notepad'
    },
    images: [
      '/images/notepad-1.jpg',
      '/images/notepad-2.jpg'
    ]
  },
  {
    id: 'line-following-robot',
    title: 'Line Following Robot with ROS2',
    shortDescription: 'Designed and implemented a line-following robot using Webots ROS2 software, winning the Most Popular Robot Award.',
    fullDescription: `This project involved designing and implementing an autonomous line-following robot using the Webots robotics simulation platform and ROS2 (Robot Operating System 2). The robot demonstrates advanced autonomous navigation capabilities and sophisticated sensor integration.

The robot utilizes computer vision algorithms to detect and follow predefined paths marked by colored lines. Advanced image processing techniques enable the robot to handle complex scenarios including intersections, curves, and obstacles along the path.

ROS2 integration provides a robust framework for sensor data processing, motor control, and decision-making algorithms. The modular architecture allows for easy expansion and modification of robot behaviors, making it suitable for various applications beyond simple line following.

The simulation environment in Webots provides realistic physics modeling and sensor simulation, allowing for comprehensive testing and validation of algorithms before physical implementation. This approach significantly reduces development time and costs while ensuring robust performance.

Key technical achievements include implementing PID control algorithms for smooth navigation, developing computer vision pipelines for reliable line detection, and creating a scalable software architecture using ROS2 best practices.`,
    tags: ['Robotics', 'ROS2', 'Computer Vision', 'Autonomous Navigation', 'Simulation'],
    technologies: ['ROS2', 'Webots', 'Python', 'OpenCV', 'PID Control', 'Computer Vision'],
    category: 'Robotics',
    featured: false,
    status: 'Completed',
    duration: '2 months',
    teamSize: '2 members',
    role: 'Robotics Engineer & Algorithm Developer',
    challenges: [
      'Implementing robust line detection in varying lighting conditions',
      'Optimizing PID control parameters for smooth navigation',
      'Handling complex path scenarios and intersections',
      'Integrating multiple sensors for comprehensive environment awareness'
    ],
    achievements: [
      'Most Popular Robot Award at IESL RAS Robot Competition 2021',
      'Demonstrated superior performance in complex navigation scenarios',
      'Successfully implemented in both simulation and physical robot'
    ],
    links: {
      github: 'https://github.com/dasuntheekshanagit/line-following-robot'
    },
    images: [
      '/images/robot-1.jpg',
      '/images/robot-2.jpg'
    ]
  }
]

export const getFeaturedProjects = () => {
  return projectsData.filter(project => project.featured)
}

export const getAllProjects = () => {
  return projectsData
}

export const getProjectById = (id) => {
  return projectsData.find(project => project.id === id)
}

export const getProjectsByCategory = (category) => {
  return projectsData.filter(project => project.category === category)
}

